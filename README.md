# ğŸ§  SentiSum â€” AnÃ¡lise de Sentimentos e SumarizaÃ§Ã£o AutomÃ¡tica de ComentÃ¡rios do YouTube  

Este projeto foi desenvolvido como parte do Trabalho de ConclusÃ£o de Curso (TCC) da **EspecializaÃ§Ã£o em InteligÃªncia Artificial e CiÃªncia de Dados** da **Universidade Federal do EspÃ­rito Santo (UFES)**.  
O sistema tem como objetivo coletar comentÃ¡rios do YouTube em portuguÃªs, analisar seus sentimentos e gerar um resumo textual automÃ¡tico que sintetiza as principais opiniÃµes expressas pelos usuÃ¡rios.

---

## ğŸ“˜ SumÃ¡rio

- [VisÃ£o Geral](#-visÃ£o-geral)
- [Arquitetura do Sistema](#-arquitetura-do-sistema)
- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [InstalaÃ§Ã£o e ExecuÃ§Ã£o](#-instalaÃ§Ã£o-e-execuÃ§Ã£o)
- [DescriÃ§Ã£o dos Arquivos Principais](#-descriÃ§Ã£o-dos-arquivos-principais)
- [Modelos Utilizados](#-modelos-utilizados)
- [Resultados Obtidos](#-resultados-obtidos)
- [LimitaÃ§Ãµes e Trabalhos Futuros](#-limitaÃ§Ãµes-e-trabalhos-futuros)
- [Autor](#-autor)

---

## ğŸŒ VisÃ£o Geral

O **SentiSum** Ã© um sistema web que integra duas tarefas fundamentais de **Processamento de Linguagem Natural (PLN)**:
1. **AnÃ¡lise de Sentimentos** â€” identifica se um comentÃ¡rio Ã© positivo ou negativo;
2. **SumarizaÃ§Ã£o AutomÃ¡tica** â€” gera um resumo textual curto e coerente das principais opiniÃµes.

Essas tarefas sÃ£o realizadas por modelos modernos baseados em **Transformers**, aplicados a textos em portuguÃªs.  
A aplicaÃ§Ã£o coleta comentÃ¡rios em tempo real atravÃ©s da **YouTube Data API v3**, processa os dados e apresenta resultados interpretÃ¡veis via uma interface web simples e intuitiva.

---

## ğŸ—ï¸ Arquitetura do Sistema

A arquitetura do projeto Ã© composta por cinco componentes principais:

```
YouTube API â†’ Coleta de ComentÃ¡rios â†’ PrÃ©-processamento â†’ 
BERT (AnÃ¡lise de Sentimentos) â†’ mT5 (SumarizaÃ§Ã£o) â†’ Flask Web App â†’ Resultado Final
```

ğŸ“Š **Fluxo Geral:**
1. O usuÃ¡rio informa um termo de busca (ex: â€œfone de ouvido Bluetoothâ€);
2. O sistema coleta comentÃ¡rios de vÃ­deos relacionados via YouTube API;
3. Os textos sÃ£o limpos e padronizados;
4. O modelo **BERT-base-portuguese-cased** classifica os comentÃ¡rios (positivo/negativo);
5. O modelo **mT5-small** gera um resumo abstrativo;
6. O resultado Ã© exibido na interface web, incluindo o resumo e a proporÃ§Ã£o de sentimentos.

---

## ğŸ§© Tecnologias Utilizadas

| Categoria | Ferramenta / Biblioteca |
|------------|--------------------------|
| **Linguagem principal** | Python 3.10 |
| **Framework web** | Flask |
| **Front-end** | HTML5, CSS3, Bootstrap 5, JavaScript |
| **APIs externas** | YouTube Data API v3 |
| **Modelos de IA** | BERT-base-portuguese-cased, mT5-small |
| **Bibliotecas de IA** | Hugging Face Transformers, PyTorch, Scikit-learn |
| **ManipulaÃ§Ã£o de dados** | Pandas, NumPy |
| **DetecÃ§Ã£o de idioma** | langdetect |
| **Versionamento** | Git + GitHub |
| **Ambiente sugerido** | Python (Ubuntu / WSL / Docker Desktop) |

---

## ğŸ“ Estrutura do Projeto

```
sentisum-tcc-ia-ufes/
â”œâ”€â”€ .vscode/
â”‚   â””â”€â”€ (Arquivos de configuraÃ§Ã£o do VS Code, como settings.json, nÃ£o visÃ­veis)
|
â”œâ”€â”€ bert-sentiment-pt/           # Pasta do modelo BERT treinado para AnÃ¡lise de Sentimentos em PortuguÃªs
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin
|   â””â”€â”€ (Outros arquivos do modelo)
|
â”œâ”€â”€ mt5-summarization-pt/        # Pasta do modelo mT5 treinado para SumarizaÃ§Ã£o em PortuguÃªs
â”‚   â”œâ”€â”€ all_results.json
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ generation_config.json
â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”œâ”€â”€ special_tokens_map.json
â”‚   â”œâ”€â”€ spiece.model
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â”œâ”€â”€ train_results.json
â”‚   â”œâ”€â”€ trainer_state.json
â”‚   â””â”€â”€ training_args.bin
|
â”œâ”€â”€ templates/                   # Arquivos HTML para a interface web
â”‚   â”œâ”€â”€ index.html               # PÃ¡gina principal (ou de entrada de dados)
â”‚   â””â”€â”€ results.html             # PÃ¡gina de resultados (sentimento e sumarizaÃ§Ã£o)
|
â”œâ”€â”€ Treinamento - BERT/          # Pasta com scripts e dados relacionados ao treino do modelo BERT
â”‚   â”œâ”€â”€ imdb-reviews-pt-br.csv   # Dataset de reviews para treinamento
â”‚   â””â”€â”€ treinamento_analise_sentimentos.py # Script de treinamento/teste do modelo BERT
|
â”œâ”€â”€ Treinamento - Sum/           # Pasta com scripts relacionados ao treino do modelo de SumarizaÃ§Ã£o
â”‚   â””â”€â”€ treinamento_sumarizacao.py # Script de treinamento/teste do modelo mT5
|
â”œâ”€â”€ venv/                        # Ambiente virtual (virtual environment)
â”‚   â””â”€â”€ (ConteÃºdo do ambiente virtual)
|
â”œâ”€â”€ app.py                       # Script principal da aplicaÃ§Ã£o (Flask)
â”œâ”€â”€ comentarios_classificados.txt # Arquivo de saÃ­da (exemplo de dados processados)
â”œâ”€â”€ requirements.txt             # Lista de dependÃªncias Python do projeto
â””â”€â”€ scripts.js                   # Script JavaScript (para a interface web)           
```

---

## âš™ï¸ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### ğŸ”¹ 1. Clonar o repositÃ³rio
```bash
git clone https://github.com/williamtccufesia/sentisum-tcc-ia-ufes.git
cd sentisum-tcc-ia-ufes
```

### ğŸ”¹ 2. Criar e ativar ambiente virtual
```bash
python -m venv venv
source venv/bin/activate  # Linux / Mac
venv\Scripts\activate     # Windows
```

### ğŸ”¹ 3. Instalar dependÃªncias
```bash
pip install -r requirements.txt
```

### ğŸ”¹ 4. Executar o servidor Flask
```bash
python app.py
```

### ğŸ”¹ 5. Acessar a aplicaÃ§Ã£o
Abra o navegador e vÃ¡ atÃ©:
```
http://127.0.0.1:5000
```

---

## ğŸ“œ DescriÃ§Ã£o dos Arquivos Principais

### ğŸ§© `app.py`
ResponsÃ¡vel por integrar todo o pipeline:
- ComunicaÃ§Ã£o com a YouTube Data API;
- Coleta e prÃ©-processamento de comentÃ¡rios;
- ExecuÃ§Ã£o dos modelos **BERT** e **mT5**;
- Retorno dos resultados ao front-end via JSON;
- Controle do fluxo de requisiÃ§Ãµes com Flask.

---

### ğŸ¤– `treinamento_analise_sentimentos.py`
Treina e ajusta o modelo **BERT-base-portuguese-cased**:
- Dataset utilizado: **IMDb-PT-BR**;
- Tarefa: classificaÃ§Ã£o binÃ¡ria (positivo / negativo);
- Frameworks: `PyTorch`, `Transformers`, `Scikit-learn`;
- MÃ©trica de desempenho: **AcurÃ¡cia â‰ˆ 93%**.

---

### ğŸ§  `treinamento_sumarizacao.py`
Treina o modelo **mT5-small** para gerar resumos abstrativos:
- Dataset utilizado: **XLSum (BBC MultilÃ­ngue)**;
- Limite de entrada: 512 tokens;
- MÃ©trica de avaliaÃ§Ã£o: **ROUGE-1 â‰ˆ 0.45**, **ROUGE-L â‰ˆ 0.42**;
- SaÃ­da: modelo salvo para inferÃªncia no Flask.

---

### ğŸ’» `index.html`
Interface principal da aplicaÃ§Ã£o web:
- Campo de busca de termo;
- BotÃ£o de execuÃ§Ã£o da anÃ¡lise;
- ExibiÃ§Ã£o dos resultados (sentimentos + resumo).

---

### âš™ï¸ `scripts.js`
Gerencia a interaÃ§Ã£o entre o front-end e o backend Flask:
- Envia requisiÃ§Ãµes `POST`;
- Recebe resultados de anÃ¡lise e resumo;
- Atualiza a interface dinamicamente.

---

## ğŸ§  Modelos Utilizados

| Modelo | FunÃ§Ã£o | Fonte |
|---------|--------|--------|
| **BERT-base-portuguese-cased** | ClassificaÃ§Ã£o de sentimentos | Neuralmind |
| **mT5-small** | SumarizaÃ§Ã£o abstrativa | Google Research |
| **IMDb-PT-BR** | Dataset de fine-tuning do BERT | AdaptaÃ§Ã£o PT-BR |
| **XLSum (PortuguÃªs)** | Dataset de fine-tuning do mT5 | BBC Research |

---

## ğŸ“Š Resultados Obtidos

- **AcurÃ¡cia BERT (validaÃ§Ã£o):** ~93%  
- **ROUGE-1 (mT5):** 0.45  
- **ROUGE-L (mT5):** 0.42  
- **Tempo mÃ©dio de execuÃ§Ã£o:** 30â€“60 segundos por requisiÃ§Ã£o  

**Exemplo de saÃ­da:**
> â€œA maioria dos usuÃ¡rios elogiou a qualidade sonora e o conforto, mas alguns relataram falhas na conexÃ£o e baixa durabilidade da bateria.â€

---

## âš ï¸ LimitaÃ§Ãµes e Trabalhos Futuros

- O modelo de sumarizaÃ§Ã£o apresenta desempenho limitado em textos curtos ou dispersos;  
- Pretende-se integrar modelos mais avanÃ§ados, como **GPT** e **Mistral**, para resumos mais fluentes;  
- Futuras versÃµes incluirÃ£o mÃ©tricas adicionais (**BLEU**, **BERTScore**) e integraÃ§Ã£o com plataformas como **Twitter** e **Reddit**.

---

## ğŸ‘¨â€ğŸ’» Autor

**William Desteffani Soares**  
EspecializaÃ§Ã£o em InteligÃªncia Artificial e CiÃªncia de Dados  
Universidade Federal do EspÃ­rito Santo (UFES) â€” Universidade Aberta Capixaba (UnAC)  

ğŸ“ GitHub: [@williamtccufesia](https://github.com/williamtccufesia)  

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© distribuÃ­do sob a licenÃ§a **MIT**.  
Consulte o arquivo `LICENSE` para mais informaÃ§Ãµes.
